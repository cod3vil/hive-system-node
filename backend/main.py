"""
Main application entry point for the Hive Arbitrage System.
Handles application lifecycle: startup, execution, and shutdown.

The scanning / signal-processing logic has been moved to QueenBee.
This file only handles infrastructure setup, monitoring, and WebSocket server.
"""

import asyncio
import signal
from typing import Optional
from datetime import datetime
import uvicorn

from backend.config.settings import get_config
from backend.storage.redis_client import RedisClient
from backend.storage.postgres_client import PostgresClient
from backend.services.exchange_client import ExchangeClient
from backend.services.exchange_manager import ExchangeManager
from backend.services.funding_service import FundingService
from backend.services.position_service import PositionService
from backend.services.equity_service import EquityService
from backend.services.balance_service import BalanceService
from backend.services.cross_exchange_spread_service import CrossExchangeSpreadService
from backend.capital.capital_allocator import CapitalAllocator
from backend.risk.risk_engine import RiskEngine
from backend.risk.liquidation_guard import LiquidationGuard
from backend.risk.drawdown_guard import DrawdownGuard
from backend.risk.funding_guard import FundingGuard
from backend.execution.trade_executor import TradeExecutor
from backend.execution.order_manager import OrderManager
from backend.core.cold_start_recovery import ColdStartRecovery
from backend.core.network_resilience import NetworkResilienceManager
from backend.utils.logger import get_logger
from backend.services.notifier import NotifyDispatcher, get_notifier
from backend.websocket.websocket_server import get_connection_manager, create_websocket_app
from backend.hive.queen_bee import QueenBee
from backend.hive.communication_bee import CommunicationBee
from backend.services.market_pair_cache import MarketPairCache


class Application:
    """Main application class managing system lifecycle."""

    def __init__(self):
        self.config = get_config()
        self.websocket_manager = get_connection_manager()
        self.logger = get_logger("Application", websocket_manager=self.websocket_manager)

        # Core clients
        self.redis_client: Optional[RedisClient] = None
        self.postgres_client: Optional[PostgresClient] = None
        self.exchange_client: Optional[ExchangeClient] = None
        self.exchange_manager: Optional[ExchangeManager] = None

        # Services
        self.funding_service: Optional[FundingService] = None
        self.position_service: Optional[PositionService] = None
        self.equity_service: Optional[EquityService] = None
        self.balance_service: Optional[BalanceService] = None
        self.spread_service: Optional[CrossExchangeSpreadService] = None

        # Capital and risk
        self.capital_allocator: Optional[CapitalAllocator] = None
        self.risk_engine: Optional[RiskEngine] = None
        self.trade_executor: Optional[TradeExecutor] = None

        # Hive
        self.queen: Optional[QueenBee] = None
        self.comm_bee: Optional[CommunicationBee] = None

        # Notifications
        self.notifier: Optional[NotifyDispatcher] = None

        # Recovery
        self.cold_start_recovery: Optional[ColdStartRecovery] = None
        self.network_resilience: Optional[NetworkResilienceManager] = None

        # Lifecycle
        self.running = False
        self.shutdown_event = asyncio.Event()
        self.monitoring_task: Optional[asyncio.Task] = None
        self.queen_task: Optional[asyncio.Task] = None
        self.websocket_task: Optional[asyncio.Task] = None
        self.comm_bee_task: Optional[asyncio.Task] = None
        self.websocket_server: Optional[uvicorn.Server] = None

    async def startup(self) -> None:
        """Application startup sequence."""
        await self.logger.info("=" * 60)
        await self.logger.info("èœ‚å·¢å¥—åˆ©ç³»ç»Ÿ - å¯åŠ¨")
        await self.logger.info("=" * 60)
        await self.logger.info(f"ç¯å¢ƒ: {self.config.environment}")
        await self.logger.info(f"äº¤æ˜“æ‰€: {self.config.exchange_name}")
        await self.logger.info(f"è´¹ç‡ç‰ˆæœ¬: {self.config.fee_version}")
        await self.logger.info(f"å¯ç”¨çš„äº¤æ˜“å¯¹: {self.config.enabled_symbols}")
        await self.logger.info(f"å•ä»“ä¸Šé™: {self.config.max_single_position_pct:.1%}")
        await self.logger.info(f"æ€»æ•å£ä¸Šé™: {self.config.max_total_exposure_pct:.1%}")
        await self.logger.info(f"æœ€å¤§å›æ’¤: {self.config.max_drawdown_pct:.1%}")

        mode = self.config.running_mode
        await self.logger.info("=" * 60)
        if mode == "testnet":
            await self.logger.info("TESTNET æ¨¡å¼ â€” è¿æ¥æµ‹è¯•ç½‘")
        elif mode == "simulation":
            await self.logger.info("SIMULATION æ¨¡å¼ â€” ä¸»ç½‘åªè¯»ï¼Œè®¢å•ä¸ºæ¨¡æ‹Ÿæˆäº¤")
        else:
            await self.logger.info("MAINNET æ¨¡å¼ â€” æ­£å¼äº¤æ˜“")
        await self.logger.info("=" * 60)

        # Initialize notification dispatcher
        self.notifier = get_notifier(self.config)
        channels = self.notifier.enabled_channels
        if channels:
            await self.logger.info(f"âœ“ é€šçŸ¥æ¸ é“å·²å¯ç”¨: {', '.join(channels)}")
        else:
            await self.logger.info("æœªé…ç½®ä»»ä½•é€šçŸ¥æ¸ é“ (Telegram / é£ä¹¦)")

        try:
            # Step 1: Redis
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–Rediså®¢æˆ·ç«¯...")
            self.redis_client = RedisClient(self.config)
            await self.redis_client.connect()
            await self.logger.info("âœ“ Rediså®¢æˆ·ç«¯å·²åˆå§‹åŒ–")

            # Step 2: PostgreSQL
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–PostgreSQLå®¢æˆ·ç«¯...")
            self.postgres_client = PostgresClient(self.config)
            await self.postgres_client.connect()
            await self.logger.info("âœ“ PostgreSQLå®¢æˆ·ç«¯å·²åˆå§‹åŒ–")

            # Step 3: Exchange client (primary)
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–äº¤æ˜“æ‰€å®¢æˆ·ç«¯...")
            self.exchange_client = ExchangeClient(self.config)
            await self.exchange_client.initialize()
            await self.logger.info("âœ“ äº¤æ˜“æ‰€å®¢æˆ·ç«¯å·²åˆå§‹åŒ–")

            # Step 4: Validate API key permissions
            await self.logger.info("æ­£åœ¨éªŒè¯APIå¯†é’¥æƒé™...")
            await self.exchange_client.validate_api_permissions()
            await self.logger.info("âœ“ APIå¯†é’¥æƒé™å·²éªŒè¯")

            # Step 4.5: Account balance
            await self.logger.info("æ­£åœ¨æŸ¥è¯¢è´¦æˆ·ä½™é¢...")
            try:
                combined = await self.exchange_client.fetch_combined_balance()
                self._startup_balance = {
                    "total": combined["total"],
                    "free": combined["free"],
                    "used": combined["used"],
                    "spot": combined["spot"],
                    "swap": combined["swap"],
                }
                await self.logger.info(
                    f"è´¦æˆ·ä½™é¢ï¼ˆUSDTï¼‰: ğŸ’° æ€»è®¡ {combined['total']:.2f} | "
                    f"ç°è´§ {combined['spot']['total']:.2f} | "
                    f"åˆçº¦ {combined['swap']['total']:.2f}"
                )
            except Exception as e:
                await self.logger.warning(f"æŸ¥è¯¢ä½™é¢å¤±è´¥: {e}")
                self._startup_balance = {
                    "total": 0, "free": 0, "used": 0,
                    "spot": {"total": 0, "free": 0, "used": 0},
                    "swap": {"total": 0, "free": 0, "used": 0},
                }

            # Step 4.6: Exchange Manager (multi-exchange, for cross-exchange)
            if self.config.enable_cross_exchange:
                await self.logger.info("æ­£åœ¨åˆå§‹åŒ–å¤šäº¤æ˜“æ‰€ç®¡ç†å™¨...")
                self.exchange_manager = ExchangeManager(self.config)
                await self.exchange_manager.initialize()
                await self.logger.info("âœ“ å¤šäº¤æ˜“æ‰€ç®¡ç†å™¨å·²åˆå§‹åŒ–")

                self.spread_service = CrossExchangeSpreadService(
                    self.exchange_manager, self.config
                )

                # Re-fetch balance from all exchanges (Binance + OKX etc.)
                try:
                    all_bal = await self.exchange_manager.fetch_all_combined_balances()
                    self._startup_balance = {
                        "total": all_bal["total"],
                        "free": all_bal["free"],
                        "used": all_bal["used"],
                        "exchanges": all_bal["exchanges"],
                    }
                    await self.logger.info(
                        f"å¤šäº¤æ˜“æ‰€ä½™é¢ï¼ˆUSDTï¼‰: ğŸ’° æ€»è®¡ {all_bal['total']:.2f}"
                    )
                    for ex_name, ex_bal in all_bal["exchanges"].items():
                        await self.logger.info(
                            f"  {ex_name.upper()}: "
                            f"ç°è´§ {ex_bal['spot']['total']:.2f} | "
                            f"åˆçº¦ {ex_bal['swap']['total']:.2f} | "
                            f"å°è®¡ {ex_bal['total']:.2f}"
                        )
                except Exception as e:
                    await self.logger.warning(f"å¤šäº¤æ˜“æ‰€ä½™é¢æŸ¥è¯¢å¤±è´¥: {e}")

            # Step 5: Services
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–æœåŠ¡...")
            self.funding_service = FundingService(
                self.exchange_client, self.redis_client, self.config
            )
            self.position_service = PositionService(
                self.redis_client, self.postgres_client,
                self.exchange_client, self.websocket_manager
            )
            self.equity_service = EquityService(
                self.redis_client, self.exchange_client,
                self.position_service, self.websocket_manager
            )
            self.balance_service = BalanceService(
                self.exchange_client, self.redis_client
            )
            await self.logger.info("âœ“ æœåŠ¡å·²åˆå§‹åŒ–")

            # Step 6: Risk guards
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–é£æ§å®ˆå«...")
            liquidation_guard = LiquidationGuard(self.exchange_client, self.config)
            drawdown_guard = DrawdownGuard(self.redis_client, self.config)
            funding_guard = FundingGuard(
                self.funding_service, self.redis_client, self.config
            )
            await self.logger.info("âœ“ é£æ§å®ˆå«å·²åˆå§‹åŒ–")

            # Step 7: Capital allocator, risk engine, trade executor
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–ç­–ç•¥å’Œæ‰§è¡Œæ¨¡å—...")
            self.capital_allocator = CapitalAllocator(
                self.redis_client, self.equity_service,
                self.exchange_client, self.config
            )
            self.risk_engine = RiskEngine(
                liquidation_guard, drawdown_guard, funding_guard,
                self.capital_allocator, self.funding_service,
                self.redis_client, self.exchange_client,
                self.config, self.websocket_manager
            )
            # Inject spread_service for cross-exchange position monitoring
            if self.spread_service:
                self.risk_engine.spread_service = self.spread_service

            order_manager = OrderManager(
                self.exchange_client, 
                shadow_mode=self.config.is_simulation,
                config=self.config
            )
            self.trade_executor = TradeExecutor(
                order_manager, self.redis_client, self.config
            )
            # Inject trade_executor into risk_engine for hard stop position closing
            self.risk_engine.set_trade_executor(self.trade_executor)
            await self.logger.info("âœ“ ç­–ç•¥å’Œæ‰§è¡Œæ¨¡å—å·²åˆå§‹åŒ–")

            # Step 8: Cold start recovery
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–å†·å¯åŠ¨æ¢å¤...")
            self.cold_start_recovery = ColdStartRecovery(
                self.redis_client, self.postgres_client,
                self.exchange_client, self.position_service,
                self.equity_service
            )
            await self.logger.info("âœ“ å†·å¯åŠ¨æ¢å¤å·²åˆå§‹åŒ–")

            # Step 8.5: Network resilience
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–ç½‘ç»œå¼¹æ€§ç®¡ç†å™¨...")
            self.network_resilience = NetworkResilienceManager(
                self.redis_client, self.exchange_client,
                self.position_service, self.equity_service,
                self.websocket_manager, self.config
            )
            await self.logger.info("âœ“ ç½‘ç»œå¼¹æ€§ç®¡ç†å™¨å·²åˆå§‹åŒ–")

            # Step 9: Clear Redis and restore from database
            await self.logger.info("=" * 60)
            await self.logger.info("æ­£åœ¨æ¸…ç©ºRediså¹¶ä»æ•°æ®åº“æ¢å¤æ•°æ®...")
            await self.logger.info("=" * 60)
            
            # Step 9.1: Clear all Redis data
            await self.logger.info("æ­£åœ¨æ¸…ç©ºRedisç¼“å­˜...")
            try:
                # Clear position-related keys
                await self.redis_client.client.delete("open_positions")
                await self.redis_client.client.delete("close_queue")
                
                # Clear position data keys
                position_keys = await self.redis_client.client.keys("position:*")
                if position_keys:
                    await self.redis_client.client.delete(*position_keys)
                    await self.logger.info(f"âœ“ å·²æ¸…ç©º {len(position_keys)} ä¸ªæŒä»“ç¼“å­˜")
                
                # Clear position by symbol keys
                symbol_keys = await self.redis_client.client.keys("position_by_symbol:*")
                if symbol_keys:
                    await self.redis_client.client.delete(*symbol_keys)
                    await self.logger.info(f"âœ“ å·²æ¸…ç©º {len(symbol_keys)} ä¸ªäº¤æ˜“å¯¹æŒä»“ç´¢å¼•")
                
                # Clear PnL keys
                await self.redis_client.client.delete("pnl:total_realized")
                await self.redis_client.client.delete("total_realized_pnl")
                await self.logger.info("âœ“ å·²æ¸…ç©ºç´¯è®¡æ”¶ç›Šç¼“å­˜")
                
                await self.logger.info("âœ“ Redisç¼“å­˜å·²æ¸…ç©º")
            except Exception as e:
                await self.logger.error(f"æ¸…ç©ºRediså¤±è´¥: {e}")
                raise
            
            # Step 9.2: Restore open positions from database
            await self.logger.info("æ­£åœ¨ä»æ•°æ®åº“æ¢å¤æŒä»“æ•°æ®...")
            try:
                # Query all open positions from database
                async with self.postgres_client.pool.acquire() as conn:
                    rows = await conn.fetch(
                        """
                        SELECT position_id, symbol, strategy_type, exchange_high, exchange_low,
                               spot_entry_price, perp_entry_price, spot_quantity, perp_quantity,
                               entry_spread_pct, target_close_spread_pct, leverage,
                               entry_timestamp, status, created_at
                        FROM positions
                        WHERE status = 'open'
                        ORDER BY created_at DESC
                        """
                    )
                    open_positions_db = [dict(row) for row in rows]
                
                if open_positions_db:
                    await self.logger.info(f"å‘ç° {len(open_positions_db)} ä¸ªæœªå¹³ä»“æŒä»“")
                    
                    for pos_row in open_positions_db:
                        position_id = str(pos_row['position_id'])
                        symbol = pos_row['symbol']
                        
                        # Reconstruct position data
                        position_data = {
                            "position_id": position_id,
                            "symbol": symbol,
                            "spot_symbol": symbol,
                            "perp_symbol": f"{symbol}:USDT",
                            "strategy_type": pos_row['strategy_type'],
                            "exchange_high": pos_row.get('exchange_high'),
                            "exchange_low": pos_row.get('exchange_low'),
                            "spot_entry_price": str(pos_row['spot_entry_price']),
                            "perp_entry_price": str(pos_row['perp_entry_price']),
                            "spot_quantity": str(pos_row['spot_quantity']),
                            "perp_quantity": str(pos_row['perp_quantity']),
                            "entry_spread_pct": str(pos_row['entry_spread_pct']) if pos_row.get('entry_spread_pct') else None,
                            "target_close_spread_pct": str(pos_row['target_close_spread_pct']) if pos_row.get('target_close_spread_pct') else None,
                            "leverage": str(pos_row['leverage']),
                            "entry_timestamp": pos_row['entry_timestamp'].isoformat() if pos_row.get('entry_timestamp') else None,
                            "status": pos_row['status'],
                            "created_at": pos_row['created_at'].isoformat() if pos_row.get('created_at') else None,
                        }
                        
                        # Store in Redis
                        await self.redis_client.set_position_data(position_id, position_data)
                        await self.redis_client.add_open_position(position_id)
                        await self.redis_client.add_position_by_symbol(symbol, position_id)
                        
                        await self.logger.info(
                            f"  âœ“ æ¢å¤æŒä»“: {symbol} ({pos_row['strategy_type']}) - {position_id[:8]}..."
                        )
                    
                    await self.logger.info(f"âœ“ å·²æ¢å¤ {len(open_positions_db)} ä¸ªæŒä»“åˆ°Redis")
                else:
                    await self.logger.info("âœ“ æ•°æ®åº“ä¸­æ²¡æœ‰æœªå¹³ä»“æŒä»“")
                    
            except Exception as e:
                await self.logger.error(f"ä»æ•°æ®åº“æ¢å¤æŒä»“å¤±è´¥: {e}")
                raise
            
            # Step 9.3: Calculate and restore total realized PnL
            await self.logger.info("æ­£åœ¨è®¡ç®—ç´¯è®¡å·²å®ç°æ”¶ç›Š...")
            try:
                # Query total realized PnL from all closed positions
                async with self.postgres_client.pool.acquire() as conn:
                    pnl_result = await conn.fetch(
                        """
                        SELECT COALESCE(SUM(realized_pnl), 0) as total_realized_pnl
                        FROM positions
                        WHERE status = 'closed' AND realized_pnl IS NOT NULL
                        """
                    )
                
                if pnl_result and len(pnl_result) > 0:
                    total_realized_pnl = float(pnl_result[0]['total_realized_pnl'])
                    # Use the correct key that RedisClient expects
                    await self.redis_client.client.set("pnl:total_realized", str(total_realized_pnl))
                    await self.logger.info(
                        f"âœ“ ç´¯è®¡å·²å®ç°æ”¶ç›Š: {total_realized_pnl:.4f} USDT "
                        f"({'ç›ˆåˆ©' if total_realized_pnl > 0 else 'äºæŸ'})"
                    )
                else:
                    await self.redis_client.client.set("pnl:total_realized", "0")
                    await self.logger.info("âœ“ ç´¯è®¡å·²å®ç°æ”¶ç›Š: 0 USDT (é¦–æ¬¡å¯åŠ¨)")
                    
            except Exception as e:
                await self.logger.error(f"è®¡ç®—ç´¯è®¡æ”¶ç›Šå¤±è´¥: {e}")
                # Set to 0 if calculation fails
                await self.redis_client.client.set("pnl:total_realized", "0")
            
            await self.logger.info("=" * 60)
            await self.logger.info("âœ“ æ•°æ®æ¢å¤å®Œæˆ")
            await self.logger.info("=" * 60)
            
            # Step 9.4: Initialize system state
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–ç³»ç»ŸçŠ¶æ€...")
            await self.redis_client.set_system_status("normal")
            await self.redis_client.set_emergency_flag(False)
            await self.redis_client.set_manual_pause(False)
            
            # Step 9.5: Initialize equity data
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–æƒç›Šæ•°æ®...")
            total_equity = await self.equity_service.calculate_total_equity()
            
            # Initialize peak equity if not set
            peak_equity = await self.redis_client.get_peak_equity()
            if peak_equity is None:
                await self.redis_client.set_peak_equity(total_equity)
                await self.logger.info(f"å³°å€¼æƒç›Šå·²åˆå§‹åŒ–: {total_equity} USDT")
            
            # Initialize daily start equity if not set
            daily_start = await self.redis_client.get_daily_start_equity()
            if daily_start is None:
                await self.redis_client.set_daily_start_equity(total_equity)
                await self.logger.info(f"æ¯æ—¥èµ·å§‹æƒç›Šå·²åˆå§‹åŒ–: {total_equity} USDT")
            
            await self.logger.info(f"âœ“ æƒç›Šæ•°æ®å·²åˆå§‹åŒ–: {total_equity} USDT")

            # Step 10: Position monitoring
            await self.logger.info("æ­£åœ¨å¯åŠ¨æŒä»“ç›‘æ§å¾ªç¯...")
            self.monitoring_task = asyncio.create_task(self._run_position_monitoring())
            await self.logger.info("âœ“ æŒä»“ç›‘æ§å¾ªç¯å·²å¯åŠ¨")

            # Step 10.5: Network resilience monitoring
            await self.logger.info("æ­£åœ¨å¯åŠ¨ç½‘ç»œå¼¹æ€§ç›‘æ§...")
            await self.network_resilience.start_monitoring()
            await self.logger.info("âœ“ ç½‘ç»œå¼¹æ€§ç›‘æ§å·²å¯åŠ¨")

            # Step 11: QueenBee â€” replaces old _run_scout_scanning
            await self.logger.info("æ­£åœ¨åˆå§‹åŒ–èœ‚ç‹...")
            market_pair_cache = MarketPairCache(self.redis_client)
            self.queen = QueenBee(
                config=self.config,
                exchange_client=self.exchange_client,
                exchange_manager=self.exchange_manager,
                trade_executor=self.trade_executor,
                capital_allocator=self.capital_allocator,
                risk_engine=self.risk_engine,
                ws_manager=self.websocket_manager,
                funding_service=self.funding_service,
                spread_service=self.spread_service,
                notifier=self.notifier,
                market_pair_cache=market_pair_cache,
                position_service=self.position_service,
                redis_client=self.redis_client,
            )
            scout_count = await self.queen.startup()
            await self.logger.info(f"âœ“ èœ‚ç‹å·²åˆå§‹åŒ– ({scout_count} ä¸ªä¾¦æŸ¥èœ‚)")
            
            # Initialize total realized PnL (preserve across restarts)
            # If Redis has a value, keep it; otherwise recover from database
            existing_pnl = await self.redis_client.get_total_realized_pnl()
            if existing_pnl == 0:
                # Try to recover cumulative realized PnL from database
                try:
                    from decimal import Decimal
                    rows = await self.postgres_client.pool.fetch(
                        "SELECT COALESCE(SUM(CAST(realized_pnl AS NUMERIC)), 0) as total "
                        "FROM positions WHERE status = 'closed' AND realized_pnl IS NOT NULL"
                    )
                    db_total = Decimal(str(rows[0]["total"])) if rows else Decimal("0")
                    if db_total != 0:
                        await self.redis_client.client.set("pnl:total_realized", str(db_total))
                        await self.logger.info(f"âœ“ ä»æ•°æ®åº“æ¢å¤ç´¯è®¡å·²å®ç°æ”¶ç›Š: {db_total} USDT")
                    else:
                        await self.logger.info("âœ“ æ€»æ”¶ç›Šåˆå§‹å€¼ä¸º0 (é¦–æ¬¡å¯åŠ¨æˆ–æ— å†å²å¹³ä»“)")
                except Exception as e:
                    await self.logger.warning(f"ä»æ•°æ®åº“æ¢å¤ç´¯è®¡æ”¶ç›Šå¤±è´¥: {e}, ä»0å¼€å§‹")
            else:
                await self.logger.info(f"âœ“ Redisä¸­å·²æœ‰ç´¯è®¡æ”¶ç›Š: {existing_pnl} USDT")

            self.queen_task = asyncio.create_task(self.queen.run())
            await self.logger.info("âœ“ èœ‚ç‹æ‰«æå¾ªç¯å·²å¯åŠ¨")

            # Step 12: WebSocket server
            await self.logger.info("æ­£åœ¨å¯åŠ¨WebSocketæœåŠ¡å™¨...")
            self.websocket_task = asyncio.create_task(self._run_websocket_server())
            await self.logger.info(f"âœ“ WebSocketæœåŠ¡å™¨å·²å¯åŠ¨ï¼Œç«¯å£ {self.config.websocket_port}")

            # Step 13: Communication Bee (if central server configured)
            if self.config.hive_server_url:
                await self.logger.info("æ­£åœ¨å¯åŠ¨é€šè®¯èœ‚...")
                self.comm_bee = CommunicationBee(
                    config=self.config,
                    redis_client=self.redis_client,
                    position_service=self.position_service,
                    equity_service=self.equity_service,
                    exchange_client=self.exchange_client,
                    exchange_manager=self.exchange_manager,
                    queen=self.queen,
                )
                self.comm_bee_task = asyncio.create_task(self.comm_bee.run())
                await self.logger.info(f"âœ“ é€šè®¯èœ‚å·²å¯åŠ¨ï¼Œç›®æ ‡: {self.config.hive_server_url}")
            else:
                await self.logger.info("æœªé…ç½®ä¸­å¤®æœåŠ¡å™¨ï¼Œé€šè®¯èœ‚æœªå¯ç”¨")

            await self.logger.info("=" * 60)
            await self.logger.info("åº”ç”¨å¯åŠ¨å®Œæˆ")
            await self.logger.info("=" * 60)
            self.running = True

            # Broadcast account balance
            await self.websocket_manager.broadcast({
                "type": "account_balance",
                "timestamp": datetime.utcnow().isoformat(),
                "data": self._startup_balance,
            })

            # Notify startup
            if self.notifier:
                await self.notifier.notify_app_startup(
                    environment=self.config.environment,
                    exchange=", ".join(self.config.enabled_exchanges),
                    scout_count=scout_count,
                    balance=self._startup_balance,
                    config=self.config,
                )

        except Exception as e:
            await self.logger.critical("åº”ç”¨å¯åŠ¨å¤±è´¥", error=str(e))
            if self.notifier:
                await self.notifier.notify_app_startup_failed(str(e))
            raise

    async def _run_position_monitoring(self) -> None:
        """Position monitoring loop - delegates to RiskEngine.monitor_positions()."""
        await self.logger.info("æŒä»“ç›‘æ§å¾ªç¯å·²å¯åŠ¨")
        try:
            # RiskEngine.monitor_positions() is itself an infinite loop
            # Just call it once and let it run
            await self.risk_engine.monitor_positions()
        except asyncio.CancelledError:
            await self.logger.info("æŒä»“ç›‘æ§å¾ªç¯å·²å–æ¶ˆ")
        except Exception as e:
            await self.logger.error("æŒä»“ç›‘æ§å¾ªç¯å‡ºé”™", error=str(e))

    async def _run_websocket_server(self) -> None:
        """Run WebSocket server for frontend connections."""
        try:
            app = create_websocket_app()
            config = uvicorn.Config(
                app,
                host=self.config.websocket_host,
                port=self.config.websocket_port,
                log_level="info",
                access_log=False
            )
            self.websocket_server = uvicorn.Server(config)
            await self.websocket_server.serve()
        except asyncio.CancelledError:
            await self.logger.info("WebSocketæœåŠ¡å™¨å·²å–æ¶ˆ")
        except Exception as e:
            await self.logger.error("WebSocketæœåŠ¡å™¨å‡ºé”™", error=str(e))

    async def run(self) -> None:
        """Main execution loop â€” waits for shutdown signal."""
        await self.logger.info("åº”ç”¨è¿è¡Œä¸­ - ç›‘æ§å’Œæ‰«æå·²æ¿€æ´»")
        await self.shutdown_event.wait()

    async def shutdown(self) -> None:
        """Graceful application shutdown."""
        await self.logger.info("=" * 60)
        await self.logger.info("æ­£åœ¨å¯åŠ¨ä¼˜é›…å…³é—­")
        await self.logger.info("=" * 60)

        if self.notifier:
            try:
                await asyncio.wait_for(self.notifier.notify_app_shutdown(), timeout=5.0)
            except (asyncio.TimeoutError, Exception):
                pass

        self.running = False

        try:
            # Stop Communication Bee
            if self.comm_bee:
                await self.logger.info("æ­£åœ¨åœæ­¢é€šè®¯èœ‚...")
                await self.comm_bee.shutdown()
                if self.comm_bee_task and not self.comm_bee_task.done():
                    self.comm_bee_task.cancel()
                    try:
                        await self.comm_bee_task
                    except asyncio.CancelledError:
                        pass
                await self.logger.info("âœ“ é€šè®¯èœ‚å·²åœæ­¢")

            # Stop QueenBee (replaces old scout task cancellation)
            await self.logger.info("æ­£åœ¨åœæ­¢èœ‚ç‹...")
            if self.queen:
                await self.queen.shutdown()
            if self.queen_task and not self.queen_task.done():
                self.queen_task.cancel()
                try:
                    await self.queen_task
                except asyncio.CancelledError:
                    pass
            await self.logger.info("âœ“ èœ‚ç‹å·²åœæ­¢")

            # Stop WebSocket server
            await self.logger.info("æ­£åœ¨åœæ­¢WebSocketæœåŠ¡å™¨...")
            if self.websocket_task and not self.websocket_task.done():
                self.websocket_task.cancel()
                try:
                    await self.websocket_task
                except asyncio.CancelledError:
                    pass
            if self.websocket_server:
                self.websocket_server.should_exit = True
            await self.logger.info("âœ“ WebSocketæœåŠ¡å™¨å·²åœæ­¢")

            # Stop position monitoring
            await self.logger.info("æ­£åœ¨åœæ­¢æŒä»“ç›‘æ§...")
            if self.monitoring_task and not self.monitoring_task.done():
                self.monitoring_task.cancel()
                try:
                    await self.monitoring_task
                except asyncio.CancelledError:
                    pass
            await self.logger.info("âœ“ æŒä»“ç›‘æ§å·²åœæ­¢")

            # Stop network resilience monitoring
            await self.logger.info("æ­£åœ¨åœæ­¢ç½‘ç»œå¼¹æ€§ç›‘æ§...")
            if self.network_resilience:
                await self.network_resilience.stop_monitoring()
            await self.logger.info("âœ“ ç½‘ç»œå¼¹æ€§ç›‘æ§å·²åœæ­¢")

            # Wait for in-flight executions
            await self.logger.info("æ­£åœ¨ç­‰å¾…è¿›è¡Œä¸­çš„æ‰§è¡Œå®Œæˆ...")
            max_wait = 30
            waited = 0
            while waited < max_wait:
                await asyncio.sleep(1)
                waited += 1
                if waited >= 5:
                    break
            await self.logger.info("âœ“ è¿›è¡Œä¸­çš„æ‰§è¡Œå·²å®Œæˆ")

            # Close exchange connections
            if self.exchange_client:
                await self.logger.info("æ­£åœ¨å…³é—­äº¤æ˜“æ‰€è¿æ¥...")
                await self.exchange_client.close()
                await self.logger.info("âœ“ äº¤æ˜“æ‰€è¿æ¥å·²å…³é—­")

            if self.exchange_manager:
                await self.logger.info("æ­£åœ¨å…³é—­å¤šäº¤æ˜“æ‰€ç®¡ç†å™¨...")
                await self.exchange_manager.close()
                await self.logger.info("âœ“ å¤šäº¤æ˜“æ‰€ç®¡ç†å™¨å·²å…³é—­")

            # Close Redis
            if self.redis_client:
                await self.logger.info("æ­£åœ¨å…³é—­Redisè¿æ¥...")
                await self.redis_client.disconnect()
                await self.logger.info("âœ“ Redisè¿æ¥å·²å…³é—­")

            # Close PostgreSQL
            if self.postgres_client:
                await self.logger.info("æ­£åœ¨å…³é—­PostgreSQLè¿æ¥...")
                await self.postgres_client.disconnect()
                await self.logger.info("âœ“ PostgreSQLè¿æ¥å·²å…³é—­")

            # Close notification sessions
            if self.notifier and self.notifier.feishu:
                await self.notifier.feishu.close()

            await self.logger.info("=" * 60)
            await self.logger.info("åº”ç”¨å…³é—­å®Œæˆ")
            await self.logger.info("=" * 60)

        except Exception as e:
            await self.logger.error("å…³é—­è¿‡ç¨‹ä¸­å‡ºé”™", error=str(e))

    def handle_signal(self, sig):
        """Handle shutdown signals."""
        print(f"\nReceived signal {sig}, initiating shutdown...")
        self.shutdown_event.set()


async def main():
    """Main entry point."""
    app = Application()

    loop = asyncio.get_event_loop()
    for sig in (signal.SIGTERM, signal.SIGINT):
        loop.add_signal_handler(sig, lambda s=sig: app.handle_signal(s))

    try:
        await app.startup()
        await app.run()
    except KeyboardInterrupt:
        print("\nKeyboard interrupt received")
    except Exception as e:
        print(f"Fatal error: {e}")
        raise
    finally:
        await app.shutdown()


if __name__ == "__main__":
    asyncio.run(main())
